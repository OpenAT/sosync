<?xml version="1.0" encoding="utf-8"?>
<root>
  <!-- 
    Microsoft ResX Schema 
    
    Version 2.0
    
    The primary goals of this format is to allow a simple XML format 
    that is mostly human readable. The generation and parsing of the 
    various data types are done through the TypeConverter classes 
    associated with the data types.
    
    Example:
    
    ... ado.net/XML headers & schema ...
    <resheader name="resmimetype">text/microsoft-resx</resheader>
    <resheader name="version">2.0</resheader>
    <resheader name="reader">System.Resources.ResXResourceReader, System.Windows.Forms, ...</resheader>
    <resheader name="writer">System.Resources.ResXResourceWriter, System.Windows.Forms, ...</resheader>
    <data name="Name1"><value>this is my long string</value><comment>this is a comment</comment></data>
    <data name="Color1" type="System.Drawing.Color, System.Drawing">Blue</data>
    <data name="Bitmap1" mimetype="application/x-microsoft.net.object.binary.base64">
        <value>[base64 mime encoded serialized .NET Framework object]</value>
    </data>
    <data name="Icon1" type="System.Drawing.Icon, System.Drawing" mimetype="application/x-microsoft.net.object.bytearray.base64">
        <value>[base64 mime encoded string representing a byte array form of the .NET Framework object]</value>
        <comment>This is a comment</comment>
    </data>
                
    There are any number of "resheader" rows that contain simple 
    name/value pairs.
    
    Each data row contains a name, and value. The row also contains a 
    type or mimetype. Type corresponds to a .NET class that support 
    text/value conversion through the TypeConverter architecture. 
    Classes that don't support this are serialized and stored with the 
    mimetype set.
    
    The mimetype is used for serialized objects, and tells the 
    ResXResourceReader how to depersist the object. This is currently not 
    extensible. For a given mimetype the value must be set accordingly:
    
    Note - application/x-microsoft.net.object.binary.base64 is the format 
    that the ResXResourceWriter will generate, however the reader can 
    read any of the formats listed below.
    
    mimetype: application/x-microsoft.net.object.binary.base64
    value   : The object must be serialized with 
            : System.Runtime.Serialization.Formatters.Binary.BinaryFormatter
            : and then encoded with base64 encoding.
    
    mimetype: application/x-microsoft.net.object.soap.base64
    value   : The object must be serialized with 
            : System.Runtime.Serialization.Formatters.Soap.SoapFormatter
            : and then encoded with base64 encoding.

    mimetype: application/x-microsoft.net.object.bytearray.base64
    value   : The object must be serialized into a byte array 
            : using a System.ComponentModel.TypeConverter
            : and then encoded with base64 encoding.
    -->
  <xsd:schema id="root" xmlns="" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:msdata="urn:schemas-microsoft-com:xml-msdata">
    <xsd:import namespace="http://www.w3.org/XML/1998/namespace" />
    <xsd:element name="root" msdata:IsDataSet="true">
      <xsd:complexType>
        <xsd:choice maxOccurs="unbounded">
          <xsd:element name="metadata">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" />
              </xsd:sequence>
              <xsd:attribute name="name" use="required" type="xsd:string" />
              <xsd:attribute name="type" type="xsd:string" />
              <xsd:attribute name="mimetype" type="xsd:string" />
              <xsd:attribute ref="xml:space" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="assembly">
            <xsd:complexType>
              <xsd:attribute name="alias" type="xsd:string" />
              <xsd:attribute name="name" type="xsd:string" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="data">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" msdata:Ordinal="1" />
                <xsd:element name="comment" type="xsd:string" minOccurs="0" msdata:Ordinal="2" />
              </xsd:sequence>
              <xsd:attribute name="name" type="xsd:string" use="required" msdata:Ordinal="1" />
              <xsd:attribute name="type" type="xsd:string" msdata:Ordinal="3" />
              <xsd:attribute name="mimetype" type="xsd:string" msdata:Ordinal="4" />
              <xsd:attribute ref="xml:space" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="resheader">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" msdata:Ordinal="1" />
              </xsd:sequence>
              <xsd:attribute name="name" type="xsd:string" use="required" />
            </xsd:complexType>
          </xsd:element>
        </xsd:choice>
      </xsd:complexType>
    </xsd:element>
  </xsd:schema>
  <resheader name="resmimetype">
    <value>text/microsoft-resx</value>
  </resheader>
  <resheader name="version">
    <value>2.0</value>
  </resheader>
  <resheader name="reader">
    <value>System.Resources.ResXResourceReader, System.Windows.Forms, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089</value>
  </resheader>
  <resheader name="writer">
    <value>System.Resources.ResXResourceWriter, System.Windows.Forms, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089</value>
  </resheader>
  <data name="Archive_finished_SyncJobs" xml:space="preserve">
    <value>-- sosync2: Archiving part 1
SET enable_seqscan = OFF;
SET enable_hashagg = OFF;
SET enable_hashjoin = OFF;
SET enable_mergejoin = OFF;
with recursive to_be_moved as (
			-- roots
			select id, parent_job_id from (
				select id, parent_job_id
				from sosync_job
				where
					parent_job_id is null
					and job_state in ('done', 'skipped')
					and job_closed_by_job_id is null
				order by id asc
				limit 100
			) first_parent

			union all

			-- children
			select child.id, child.parent_job_id
			from sosync_job child
			inner join to_be_moved parent on parent.id = child.parent_job_id
		),
moved_rows as (
	delete from sosync_job src
	using to_be_moved
	where src.id = to_be_moved.id
	returning src.*
),
inserted as (
	insert into sosync_job_archive (
		id,
		parent_job_id,
		job_closed_by_job_id,
		job_date,
		job_fetched,
		job_priority,
		job_source_system,
		job_source_model,
		job_source_record_id,
		job_source_target_record_id,
		job_source_sosync_write_date,
		job_source_fields,
		job_source_type,
		job_source_type_info,
		job_source_merge_into_record_id,
		job_source_target_merge_into_record_id,
		job_start,
		job_end,
		job_duration,
		job_run_count,
		job_log,
		job_state,
		job_error_code,
		job_error_text,
		parent_path,
		child_job_start,
		child_job_end,
		child_job_duration,
		sync_source_system,
		sync_source_model,
		sync_source_record_id,
		sync_source_merge_into_record_id,
		sync_target_system,
		sync_target_model,
		sync_target_record_id,
		sync_target_merge_into_record_id,
		sync_source_data,
		sync_target_data_before,
		sync_target_data_after,
		sync_target_request,
		sync_target_answer,
		sync_start,
		sync_end,
		sync_duration,
		create_uid,
		create_date,
		write_uid,
		write_date
	)
	select
		id,
		parent_job_id,
		job_closed_by_job_id,
		job_date,
		job_fetched,
		job_priority,
		job_source_system,
		job_source_model,
		job_source_record_id,
		job_source_target_record_id,
		job_source_sosync_write_date,
		job_source_fields,
		job_source_type,
		job_source_type_info,
		job_source_merge_into_record_id,
		job_source_target_merge_into_record_id,
		job_start,
		job_end,
		job_duration,
		job_run_count,
		job_log,
		job_state,
		job_error_code,
		job_error_text,
		parent_path,
		child_job_start,
		child_job_end,
		child_job_duration,
		sync_source_system,
		sync_source_model,
		sync_source_record_id,
		sync_source_merge_into_record_id,
		sync_target_system,
		sync_target_model,
		sync_target_record_id,
		sync_target_merge_into_record_id,
		sync_source_data,
		sync_target_data_before,
		sync_target_data_after,
		sync_target_request,
		sync_target_answer,
		sync_start,
		sync_end,
		sync_duration,
		create_uid,
		create_date,
		write_uid,
		write_date
	from moved_rows
	returning id
)
select count(id) from inserted;</value>
  </data>
  <data name="Archive_finished_SyncJobs_Part_2" xml:space="preserve">
    <value>-- sosync2: Archiving part 2
SET enable_seqscan = OFF;
SET enable_hashagg = OFF;
SET enable_hashjoin = OFF;
SET enable_mergejoin = OFF;
with recursive to_be_moved as (
			-- roots
			select id, parent_job_id from (
				select id, parent_job_id
				from sosync_job
				where
					parent_job_id is null
					and job_state in ('done', 'skipped')
					and job_closed_by_job_id is not null
				order by id asc
				limit 100
			) first_parent

			union all

			-- children
			select child.id, child.parent_job_id
			from sosync_job child
			inner join to_be_moved parent on parent.id = child.parent_job_id
		),
moved_rows as (
	delete from sosync_job src
	using to_be_moved
	where src.id = to_be_moved.id
	returning src.*
),
inserted as (
	insert into sosync_job_archive (
		id,
		parent_job_id,
		job_closed_by_job_id,
		job_date,
		job_fetched,
		job_priority,
		job_source_system,
		job_source_model,
		job_source_record_id,
		job_source_target_record_id,
		job_source_sosync_write_date,
		job_source_fields,
		job_source_type,
		job_source_type_info,
		job_source_merge_into_record_id,
		job_source_target_merge_into_record_id,
		job_start,
		job_end,
		job_duration,
		job_run_count,
		job_log,
		job_state,
		job_error_code,
		job_error_text,
		parent_path,
		child_job_start,
		child_job_end,
		child_job_duration,
		sync_source_system,
		sync_source_model,
		sync_source_record_id,
		sync_source_merge_into_record_id,
		sync_target_system,
		sync_target_model,
		sync_target_record_id,
		sync_target_merge_into_record_id,
		sync_source_data,
		sync_target_data_before,
		sync_target_data_after,
		sync_target_request,
		sync_target_answer,
		sync_start,
		sync_end,
		sync_duration,
		create_uid,
		create_date,
		write_uid,
		write_date
	)
	select
		id,
		parent_job_id,
		job_closed_by_job_id,
		job_date,
		job_fetched,
		job_priority,
		job_source_system,
		job_source_model,
		job_source_record_id,
		job_source_target_record_id,
		job_source_sosync_write_date,
		job_source_fields,
		job_source_type,
		job_source_type_info,
		job_source_merge_into_record_id,
		job_source_target_merge_into_record_id,
		job_start,
		job_end,
		job_duration,
		job_run_count,
		job_log,
		job_state,
		job_error_code,
		job_error_text,
		parent_path,
		child_job_start,
		child_job_end,
		child_job_duration,
		sync_source_system,
		sync_source_model,
		sync_source_record_id,
		sync_source_merge_into_record_id,
		sync_target_system,
		sync_target_model,
		sync_target_record_id,
		sync_target_merge_into_record_id,
		sync_source_data,
		sync_target_data_before,
		sync_target_data_after,
		sync_target_request,
		sync_target_answer,
		sync_start,
		sync_end,
		sync_duration,
		create_uid,
		create_date,
		write_uid,
		write_date
	from moved_rows
	returning id
)
select count(id) from inserted;</value>
  </data>
  <data name="CheckModelQuery" xml:space="preserve">
    <value>-- sosync2: Check sosync_job error and retry count
select
	true
from
	sosync_job
where
	job_source_record_id = @id
	and job_source_model = @model
	and job_state in ('new', 'error', 'error_retry')
limit 1</value>
  </data>
  <data name="ClosePreviousJobs_Update_SCRIPT" xml:space="preserve">
    <value>with updated_rows as (
	update sosync_job
	set
		job_state = 'skipped'
		,job_log = @job_log
		,job_closed_by_job_id = @job_closed_by_job_id
		,write_date = @write_date
		,job_start = now() at time zone 'utc'
		,job_end = now() at time zone 'utc'
	where
		job_source_sosync_write_date &lt; @job_source_sosync_write_date
		and job_source_system = @job_source_system
		and job_source_model = @job_source_model
		and job_source_record_id = @job_source_record_id
		and job_state in ('new', 'error', 'error_retry')
	returning id
)
select count(*) affected_rows from updated_rows;</value>
  </data>
  <data name="GetFirstOpenSynJobAndChildren_SELECT" xml:space="preserve">
    <value>with recursive job as (
	-- roots
	select * from (
		select *
		from sosync_job
		where parent_job_id is null and job_state in ('new', 'inprogress') and create_date + interval '5 seconds' &lt; current_timestamp
        order by job_state, job_priority desc, job_date desc
        limit %LIMIT%
	) first_parent

	union all
	
	-- children
	select child.*
	from sosync_job child
	inner join job parent on parent.id = child.parent_job_id
)
select * from job order by job_priority desc, job_date asc;</value>
  </data>
  <data name="MSSQL_Merge_PersonGrTags" xml:space="preserve">
    <value>WITH target AS (
	SELECT * FROM fson.gr_tag_Personen
	WHERE PersonID = @PersonID
)
MERGE target
USING (
	SELECT gr_tagID
	FROM fson.gr_tag
	WHERE fson.gr_tag.gr_tagID IN (%TAGLIST%)
) AS source
ON
	(source.gr_tagID = target.gr_tagID)

WHEN NOT MATCHED THEN
	INSERT (PersonID, gr_tagID)
	VALUES (@PersonID, source.gr_tagID)

WHEN NOT MATCHED BY SOURCE THEN
	DELETE
;</value>
  </data>
  <data name="MSSQL_Merge_ProductTemplateGroups" xml:space="preserve">
    <value>WITH target AS (
	SELECT * FROM fson.product_template_zGruppeDetail
	WHERE product_templateID = @product_templateID
)
MERGE target
USING (
	SELECT zGruppeDetailID
	FROM #temp_table_name
) AS source
ON
	(source.zGruppeDetailID = target.zGruppeDetailID)

WHEN NOT MATCHED THEN
	INSERT (product_templateID, zGruppeDetailID)
	VALUES (@product_templateID, source.zGruppeDetailID)

WHEN NOT MATCHED BY SOURCE THEN
	DELETE
;</value>
  </data>
  <data name="MSSQL_Merge_SaleOrderGroups" xml:space="preserve">
    <value>WITH target AS (
	SELECT * FROM fson.sale_order_line_zGruppeDetail
	WHERE sale_order_lineID = @sale_order_lineID
)
MERGE target
USING (
	SELECT zGruppeDetailID
	FROM #temp_table_name
) AS source
ON
	(source.zGruppeDetailID = target.zGruppeDetailID)

WHEN NOT MATCHED THEN
	INSERT (sale_order_lineID, zGruppeDetailID)
	VALUES (@sale_order_lineID, source.zGruppeDetailID)

WHEN NOT MATCHED BY SOURCE THEN
	DELETE
;</value>
  </data>
</root>